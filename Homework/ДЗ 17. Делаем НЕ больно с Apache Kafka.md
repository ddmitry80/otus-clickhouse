# ДЗ 17. Делаем НЕ больно с Apache Kafka

Материалы:
- https://github.com/conduktor/kafka-stack-docker-compose
- https://github.com/AlexeyFerum/teaching_time/wiki/Sbornaya-solyanka#clickhouse--kafka-on-yc


# Создание потока данных

Для данного ДЗ сделан отдельный поток-источник в NiFi, под названием `SampleJson2Kafka`, расположенный в `project_work/nifi/templates/SampleJson2Kafka.json`

![SampleJson2Kafka](img/2025-04-06%20221058.png)

# На стороне Clickhouse

Запускать буду на кластере project_work. Попробую и одиночный сервер, и кластерный вариант

## Одиночный сервер

```sql
CREATE DATABASE kafka ON CLUSTER c2sh2rep;

DROP TABLE IF EXISTS kafka.SampleJson_ext NO DELAY; -- on cluster c2sh2rep NO DELAY;

SET allow_experimental_json_type = 1;
DROP TABLE IF EXISTS kafka.SampleJson_ext NO DELAY;
CREATE TABLE kafka.SampleJson_ext
(
    json JSON
) ENGINE = Kafka()
SETTINGS
    kafka_broker_list = 'PLAINTEXT://kafka:29092'
    , kafka_topic_list = 'SampleJson2Kafka'
    , kafka_group_name = 'nifi.dev.SampleJson2Kafka.3'
    , kafka_handle_error_mode='stream'
    , kafka_format = 'JSONAsObject'
;

-- Проверяем работоспособность
set stream_like_engine_allow_direct_select = 1;
select "json", _topic, _key, _offset, _partition, _timestamp, _raw_message from kafka.SampleJson_ext;

-- Сюда сохраняем данные из Kafka
SET allow_experimental_json_type = 1;
DROP TABLE IF EXISTS stg.SampleJson NO DELAY;
CREATE TABLE stg.SampleJson
(
    json String
    , _topic LowCardinality(String)
    , _key String  -- Ключ сообщения
    , _offset UInt64  -- Смещение сообщения
    , _partition UInt64  -- Партиция темы Kafka
    , _timestamp Nullable(DateTime) -- Метка времени сообщения
    , created_at DateTime DEFAULT now()
)
ENGINE = MergeTree() ORDER BY (created_at);

DROP VIEW IF EXISTS stg.SampleJson_mv;
CREATE MATERIALIZED VIEW stg.SampleJson_mv TO stg.SampleJson
AS SELECT
    --id
    json
    , _topic
    , _key  -- Ключ сообщения
    , _offset  -- Смещение сообщения
    , _partition  -- Партиция темы Kafka
    , _timestamp  -- Метка времени сообщения
FROM kafka.SampleJson_ext;
attach TABLE  kafka.SampleJson_ext;

-- Проверяем работу
SELECT json, created_at FROM stg.SampleJson ORDER BY created_at DESC LIMIT 10;

json                                                        |created_at         |
------------------------------------------------------------+-------------------+
{"dttm":"1715894946835","txt":"Mervin Koss II"}             |2025-04-06 18:57:57|
{"dttm":"1723161966710","txt":"Zelda II: Adventure of Link"}|2025-04-06 18:57:57|
{"dttm":"1716167974098","txt":"Komondor"}                   |2025-04-06 18:57:57|
{"dttm":"1732130970618","txt":"A Link to the Past"}         |2025-04-06 18:57:57|
{"dttm":"1730574061645","txt":"Vizsla"}                     |2025-04-06 18:57:57|
{"dttm":"1720538045531","txt":"Twilight Princess"}          |2025-04-06 18:57:57|
{"dttm":"1740851811239","txt":"wasp"}                       |2025-04-06 18:57:57|
{"dttm":"1737646936425","txt":"Little, Frami and Gottlieb"} |2025-04-06 18:57:57|
{"dttm":"1727948854844","txt":"Miss Lemuel Rath"}           |2025-04-06 18:57:57|
{"dttm":"1726733732590","txt":"MacGyver-Larson"}            |2025-04-06 18:57:57|
```

## Работа в кластерном режиме

В документации написано, что в случае реплицированной таблицы матвью будет заполняться только одной репликой. https://clickhouse.com/docs/sql-reference/statements/create/view#in-replicated-db
Предположу, это должно позволить заполнять таблицу через KafkaEngine на кластере смешанной топологии.

```sql
---------- cluster mode 
DROP TABLE IF EXISTS kafka.SampleJson_cl_ext ON CLUSTER c2sh2rep NO DELAY;
CREATE TABLE kafka.SampleJson_cl_ext ON CLUSTER c2sh2rep
(
    id UInt64
) ENGINE = Kafka()
SETTINGS
    kafka_broker_list = 'PLAINTEXT://kafka:29092'
    , kafka_topic_list = 'SampleJson2Kafka'
    , kafka_group_name = 'nifi.dev.SampleJson2Kafka_cl.1'
    , kafka_handle_error_mode='stream'
    , kafka_format = 'Raw'
    , kafka_num_consumers = 2
;

-- Проверяем работу
set stream_like_engine_allow_direct_select = 1;
select id, _raw_message, _topic, _key, _offset, _partition, _timestamp from kafka.SampleJson_cl_ext;

-- Реплицированная таблица как подложка для шардированной
DROP TABLE IF EXISTS stg.SampleJson_rep NO DELAY;
CREATE TABLE stg.SampleJson_rep ON CLUSTER c2sh2rep
(
    json String
    , _topic LowCardinality(String)
    , _key String  -- Ключ сообщения
    , _offset UInt64  -- Смещение сообщения
    , _partition UInt64  -- Партиция темы Kafka
    , _timestamp Nullable(DateTime) -- Метка времени сообщения
    , created_at DateTime DEFAULT now()
)
ENGINE = ReplicatedMergeTree('/clickhouse/shard_{shard_c2sh2rep}/{database}/{table}','{replica_c2sh2rep}')
PARTITION BY toYYYYMMDD(created_at)
ORDER BY created_at;

-- Распределенная таблица поверх реплицированной
DROP TABLE IF EXISTS stg.SampleJson_sh ON CLUSTER c2sh2rep;
CREATE TABLE stg.SampleJson_sh ON CLUSTER c2sh2rep
AS stg.SampleJson_rep
ENGINE = Distributed(c2sh2rep, stg, SampleJson_rep, rand());

select * from stg.SampleJson_sh;

CREATE MATERIALIZED VIEW stg.SampleJson_cl_mv ON CLUSTER c2sh2rep TO stg.SampleJson_rep 
AS SELECT
    _raw_message as json
    , _topic  -- Имя топика
    , _key  -- Ключ сообщения
    , _offset  -- Смещение сообщения
    , _partition  -- Партиция темы Kafka
    , _timestamp  -- Метка времени сообщения
FROM kafka.SampleJson_cl_ext;

select hostName() AS hostname, shardNum() AS shard_number, t.* from stg.SampleJson_sh t order by created_at desc;

SELECT json, created_at FROM stg.SampleJson_sh t order by created_at desc limit 10;

json                                                                                           |created_at         |
-----------------------------------------------------------------------------------------------+-------------------+
{"dttm":1735078199681,"txt":"neque"}                                                           |2025-04-06 19:07:32|
{"dttm":1726592792346,"txt":"Oracle of Seasons - Oracle of Ages"}                              |2025-04-06 19:07:32|
{"dttm":1730838807908,"txt":"Deandrea Douglas"}                                                |2025-04-06 19:07:32|
{"dttm":1715248833357,"txt":"Brighthurst Technical College"}                                   |2025-04-06 19:07:32|
{"dttm":1736266082587,"txt":"O Romeo, Romeo! wherefore art thou Romeo?."}                      |2025-04-06 19:07:32|
{"dttm":1742215099762,"txt":"Zelda II: Adventure of Link"}                                     |2025-04-06 19:07:32|
{"dttm":1726308639334,"txt":"Marblewald University"}                                           |2025-04-06 19:07:32|
{"dttm":1736194767335,"txt":"snail"}                                                           |2025-04-06 19:07:32|
{"dttm":1719047260212,"txt":"Dulce et Decorum Est"}                                            |2025-04-06 19:07:32|
{"dttm":1743706258594,"txt":"Whiteboards are white because Chuck Norris scared them that way."}|2025-04-06 19:07:32|

select count(*) from stg.SampleJson_sh;

count()|
-------+
   8700|
```

## Реализацие загрузки из Kafka без использования Kafka Engine

Данный процесс был реализован в предыдущем ДЗ, с использованием NiFi
