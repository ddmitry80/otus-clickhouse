# ДЗ 16. Загрузка данных в Clickhouse

В качестве DI/ETL инструмента для ДЗ выбрал Apache NiFi

Взял за основу свой учебный стенд, что делал для коллег. Внутри одной Process Group NiFi выгружает поток синтетических данных в Kafka, а второй Process Group этот поток загружает в БД. Немного упростил, выкинув пост-обработку, всякие нюансы, имитирующие контур заказчика, оставив главную сутевую часть.

# Описание стенда

Стенд сконфигурирован в отдельном каталоге репозитория: /project_work. Предполагаю, что подготовленная инфраструктура станет частью проектной работы.
Поднят кластер из 4 Clickhouse, испольуется конфигурация с 2 шардами и 2 репликами на шард.
Добавлен NiFi как ETL инструмен, Kafka (в режиме без Zookeper), Kafka-UI для более удобного контроля происходящего.
Есть мониторинг, для контроля загрузки кластера, и как часть будущего проекта. Плюс, кластер без мониторинга - как минимум, странно.
Детально, как подключиться к той или иной подсистеме кластера, указано в README.md

# Интеграция

## Выгрузка данных в Kafka

Выгрузка процесса находится в /project_work/nifi/templates/Sample2Kafka.json

![Скриншот](img/2025-04-06%20161133.png)

## Загрузка из Kafka в Clickhouse

Минимальный процесс: ConsumeKafkaRecord -> MergeRecord -> PutDatabaseRecord

В данном варианте приходящая запись (в нашем случае в Avro) разворачивается с использованием приложенной схемы, и переупаковывается в Json. Далее MergeRecord объединяет набор данных в пакет (микробатч), и этот пакет сохраняется в БД через PutDatabaseRecord. В случае другой БД здесь еще был бы ExecuteSQL блок, с ограничением на Connection в 1 запись, что позволило бы сразу после записи батча в БД запускать обрабатывающий ее код, например для переливки из stg в ods слой. В Clickhouse же данную процедуру можно сделать непосредственно, на базе матвью.

Процесс экспортирован в /project_work/nifi/templates/SampleKafka2ClickHouse.json

![Скриншот SampleKafka2ClickHouse](img/2025-04-06%20161729.png)

Настройка ConnectionPool
![Настройка ConnectionPool](img/2025-04-06%20162954.png)

## Код на стороне Clickhouse

```sql
CREATE DATABASE stg ON CLUSTER c2sh2rep;

-- Создаем реплицированную таблицу как подложку для шардированной
DROP TABLE IF EXISTS stg.samplekafka2CH_rep3  ON CLUSTER c2sh2rep NO DELAY;
CREATE TABLE stg.samplekafka2CH_rep3 ON CLUSTER c2sh2rep
(
    dttm DateTime
    , txt String
    , created_at DateTime DEFAULT now()
)
ENGINE = ReplicatedMergeTree('/clickhouse/shard_{shard_c2sh2rep}/{database}/{table}','{replica_c2sh2rep}')
PARTITION BY toYYYYMMDD(dttm)
ORDER BY dttm;

-- Распределенная таблица поверх реплицированной
DROP TABLE IF EXISTS stg.samplekafka2CH_sh ON CLUSTER c2sh2rep NO DELAY;
CREATE TABLE stg.samplekafka2CH_sh ON CLUSTER c2sh2rep
AS stg.samplekafka2CH_rep3
ENGINE = Distributed(c2sh2rep, stg, samplekafka2CH_rep3, rand());

-- Количество данных
select count(*) from stg.samplekafka2CH_sh

count()|
-------+
    183|

-- Раскладка данных по шардам
SELECT hostName() AS hostname, shardNum() AS shard_number, count(*) AS cnt FROM stg.samplekafka2CH_sh AS t GROUP BY 1, 2;

hostname    |shard_number|cnt|
------------+------------+---+
01717d078256|           2|102|
b2bd4fb01852|           1| 86|

-- Смотрим, что залилось
SELECT * FROM stg.samplekafka2CH_sh ORDER BY created_at DESC limit 10;

dttm               |txt                                       |created_at         |
-------------------+------------------------------------------+-------------------+
2024-07-08 09:52:05|Lemke and Sons                            |2025-04-06 13:51:33|
2025-02-16 08:30:26|horse                                     |2025-04-06 13:51:31|
2024-04-26 22:03:29|Chow                                      |2025-04-06 13:51:29|
2024-04-15 15:17:37|porpoise                                  |2025-04-06 13:51:27|
2024-12-12 08:40:59|Schimmel-Schumm                           |2025-04-06 13:51:25|
2024-04-12 14:18:01|Clearcourt TAFE                           |2025-04-06 13:51:23|
2024-06-24 01:31:27|Many Waters                               |2025-04-06 13:51:21|
2024-09-18 21:51:47|Sue Gottlieb                              |2025-04-06 13:51:19|
2025-01-19 16:05:14|O Romeo, Romeo! wherefore art thou Romeo?.|2025-04-06 13:51:17|
2025-03-15 06:32:12|The Line of Beauty                        |2025-04-06 13:51:15|
```

Количество данных суммарно по шардам могут немного не совпадать с общим числом, т.к. процесс заливки во время выполнения запросов я не останавливал.
Еще, обращаем внимание, что время в created_at - не совпадает по TZ с текущим. Нужно это как-то учитывать в будущем, вижу как потенциальный источник ошибок.
